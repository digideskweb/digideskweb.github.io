{"response": [{"author_name": "Arron", "gravatar_hash": "198d6d4fed2012d939b47e63e561082f", "author_url": "http://www.unkwndesign.com", "date": "Jan 17, 2009", "message": "With the last company I worked for, a tech support company, they had all the servers on raid 1 or 10, but they had never tested the system to ensure it worked nor did they know what to do when something went wrong.  When I realized this I went to one of the important servers and pulled a drive, as expected my monitoring software immediatly sent a notifacation to the appropriate people, who responded.  However they didn't know what to do and spent 2 1/2 days trying to figure out what to do, with a total downtime of 8 hours (mostly at night so no loss there).  When they fixed it, the wrong way, they ghosted the working drive, wiped it clean, rebuilt the array, then cloned the image back.  I got everyone together and pulled the drive again, after the inital panic settled down I showed them the correct way to fix it, reinsert the drive and walk away.\n\nThe moral of this story is that backups are worthless if you don't a)verify they work and b) know how to use them.\n\nSo good job on figuring it BEFORE you needed it."}, {"author_name": "Jeff Atwood", "gravatar_hash": "51d623f33f8b83095db84ff35e15dbe8", "author_url": "http://www.codinghorror.com/blog/", "date": "Jan 17, 2009", "message": "Arron, that's hilarious.. ly bad! Sheesh!"}, {"author_name": "Joshua Hayworth", "gravatar_hash": "220060b0a6dee1f805e00be06f34b965", "author_url": "http://www.joshuahayworth.com", "date": "Jan 17, 2009", "message": "Hey Jeff?\n\nWould there be any chance you would be willing to compare/contrast your (and Joel's) RAID experience with something like the Google File System?\n\nSee reference here: http://labs.google.com/papers/gfs.html\n\nI'm considering a set up similar to yours for my server environment. The choice I'm debating over, however, is:\n\n* A set of \"standard\" servers like you've built\n* Several smaller, commodity servers (off the shelf parts from NewEgg.com) with a custom written GFS-like data subsystem. [i.e. http://www.codinghorror.com/blog/archives/000814.html]\n\nI would love to read your thoughts.\n\nJoshua"}, {"author_name": "Zizzencs", "gravatar_hash": "a2434ff7cd1dba4d58aadd4a5d8d5fee", "author_url": null, "date": "Jan 17, 2009", "message": "Jeff, I don't want to disappoint but hot-swap shouldn't require a reboot.\n\nSuggestions:\n\n- Try to start the RAID manager application after you remove the drive. You might need to set the missing drive faulty or something similar.\n\n- Try to update the RAID controller's drivers. That might help.\n\n- Try to update the RAID controller's AND the discs' firmware.\n\n- Ask for support from IBM. :-)"}, {"author_name": "Jeff Atwood", "gravatar_hash": "51d623f33f8b83095db84ff35e15dbe8", "author_url": "http://www.codinghorror.com/blog/", "date": "Jan 17, 2009", "message": "> but hot-swap shouldn\u2019t require a reboot.\n\nI don't think the Lenovo 1U entry-level server is *intended* to be a hot-swap server."}, {"author_name": "Jim", "gravatar_hash": "60ccc94d853cb79dd5e6e013c006e78e", "author_url": null, "date": "Jan 17, 2009", "message": "Does the web server need that much capacity if the database server is handling the bulk of the storage? You might consider getting 10000RPM drives with less capacity to see a benefit of improved speed for the the sync and for the server in general."}, {"author_name": "Peter LaComb", "gravatar_hash": "fcffc30cefd7a6870fb97c4ddee01227", "author_url": null, "date": "Jan 17, 2009", "message": "Jeff,\n\npages 32-34 of the user guide show that some models of the 1-U server have hot-swap capable drives.\n\nftp://ftp.software.ibm.com/pc/pccbbs/thinkcentre_software/rs110_user_guide_en.pdf\n\nThe hot-swap drives have the typical locking latch, the 'simple swap' drives have pull-handles."}, {"author_name": "Nick Berardi", "gravatar_hash": "906432cc1eb080f5e5343438f654189e", "author_url": "http://www.coderjournal.com", "date": "Jan 17, 2009", "message": "If you are just doing a simple mirror RAID, try the Windows Software RAID.  Joel has mentioned software RAID a couple times in your Podcast.  And I have to agree with him, for simple RAID configurations you cannot beat the software RAID.  They are usually less buggy, and work with the latest drivers for your hard disk."}, {"author_name": "Brent Ozar", "gravatar_hash": "77f776c2eaf0cc691e8a0880bb8a191f", "author_url": "http://www.brentozar.com", "date": "Jan 17, 2009", "message": "To take it to the next level, you can use IBM Director.  It's a software package that runs agents on each monitored server (not sure if they completely support the Lenovo boxes, but I bet a reader knows).  Whenever a part fails, the Director server phones home to IBM, orders the part, and dispatches a tech.  You can set the address of each system so that the tech goes to the right address, and for lights-out datacenters, you can preapprove IBM to go in and replace the part.  It works pretty well for routine problems like hard drives in the RD120/346 series.  The dead drive is identified by a red light, and the tech knows he can pull it and replace it.  The rebuild starts automatically.  They usually get you on the phone just to be safe though.\n\nIt doesn't work as well for more complex problems.  I've had instances where IBM repeatedly replaced the same drive over and over, not stopping to check history to see if something bigger might be happening, like a failing RAID card or backplane.\n\nBut the phone-home stuff rocks though."}, {"author_name": "daub815", "gravatar_hash": "004eecdcc3bdfec4eb0e860ac2688b92", "author_url": "http://www.kevindaub.com", "date": "Jan 17, 2009", "message": "Just remember what RAID is in your case.  In JournalSpace's case, it was fault-tolerance used as a backup solution.  Hopefully, you have another backup solution besides mirroring.\n\nhttp://hardware.slashdot.org/article.pl?sid=09/01/02/1546214"}, {"author_name": "Arron", "gravatar_hash": "198d6d4fed2012d939b47e63e561082f", "author_url": "http://www.unkwndesign.com", "date": "Jan 17, 2009", "message": "@Jeff they learned their lesson, now they test all their backup systems before they put them into production."}, {"author_name": "Simucal", "gravatar_hash": "503dc458e66746c5ac681e7057d209dd", "author_url": null, "date": "Jan 17, 2009", "message": "@Arron, \n\n\"The moral of this story is that backups are worthless if you don\u2019t a)verify they work and b) know how to use them.\"\n\nRAID != Backups!  \n\nYou can have the best RAID system in the world but if there is a fire, electrical malfunction that fries all system internals or anything else catastrophic, etc.. you will lose everything.\n\nRAID and the word backup don't need to go in the same sentence.  That thinking has led to much heartache in the past.\n\nHow often is the SO database backed up offsite?"}, {"author_name": "Michael Stum", "gravatar_hash": "411cf599ae9fe1ef80d40644c83c0f78", "author_url": "http://www.Stum.de", "date": "Jan 17, 2009", "message": "@daub815: Whoa, that is bad. Relying on RAID-1 for Backups is stupid. But truth be told, I fell into that same trap 5 or 6 years ago. We sold a server, but the backup drive was not in place yet. No Problem, we have RAID-1, so what should happen if we just let it run for a few weeks while we wait for the equipment?\n\nWell, both drives were IBM Deskstar DTLA-307045, aka. Deathstar. Both failed on the same day. Sadly, the second one failed before we could replace the first one.\n\nThat was a hard lesson learned :)"}, {"author_name": "Arron", "gravatar_hash": "198d6d4fed2012d939b47e63e561082f", "author_url": "http://www.unkwndesign.com", "date": "Jan 17, 2009", "message": "@Simucal you are correct, maybe backup was not the exactly correct term so s/backup/redundancy"}, {"author_name": "John Mark Schofield", "gravatar_hash": "10e37442232ec308f482ba9f200f274b", "author_url": "http://blog.sudosu.net", "date": "Jan 17, 2009", "message": "Be aware that not all RAID cards sold (including by IBM) are true hardware RAID. The more inexpensive ones have a hardware component, but implement some of the RAID logic in the Windows driver. This means that strange things can happen. I had an IBM 1U server (x306) running Win2k3 Server suddenly start showing me a C: and an E: (the two physical hard drives) instead of one mirrored drive.\n\nGoogle for \"fakeraid\" for more information. I took a quick look, and wasn't able to tell if your card is true hardware raid or fakeraid."}, {"author_name": "Jeff Atwood", "gravatar_hash": "51d623f33f8b83095db84ff35e15dbe8", "author_url": "http://www.codinghorror.com/blog/", "date": "Jan 17, 2009", "message": "> IBM Deskstar DTLA-307045, aka. Deathstar. Both failed on the same day. Sadly, the second one failed before we could replace the first one.\n\nOuch. Yes, RAID is no replacement for a real backup strategy; it's mostly a tool to maximize uptime.\n\n> wasn\u2019t able to tell if your card is true hardware raid or fakeraid.\n\nNo OS drivers are necessary for it to work (that I could see), so I believe it's real raid -- albeit low-end."}, {"author_name": "Brad", "gravatar_hash": "a733ce6210c28924181fadd757810335", "author_url": null, "date": "Jan 17, 2009", "message": "+1 on \"Google for \"fakeraid\"\". If you have raid \"integrated\" into your motherboard - chances are it's fakeraid. Not necessarily a bad thing, but fakeraid chews up CPU and it's a pita to fix if there's a software bug found in the controller.\n\nOn the topic of backup's - the simplest tool I've found so far for windows is rsnapshot - works similar to linux's rsync in that it checks timestamps/filesizes/etc and only copies files that have changed up to your backup (remote) drive.\n\nThe downside is I have no idea if you could do an incremental backup of your database - I'm guessing that it's an all or none kind of thing.\n\n-Brad"}, {"author_name": "Jeff Atwood", "gravatar_hash": "51d623f33f8b83095db84ff35e15dbe8", "author_url": "http://www.codinghorror.com/blog/", "date": "Jan 17, 2009", "message": "> If you have raid \u201cintegrated\u201d into your motherboard - chances are it\u2019s fakeraid\n\nI agree, and this is one major reason why I didn't go with some of the default SuperMicro stuff -- you have to buy a real raid controller, unless you want to rely on the RAID functionality that's embedded in the Intel chipset itself.\n\nOn the Lenovo 1U there's a mini-PCI card containing the LSI 1064E raid controller, as stated in the post."}, {"author_name": "mgb", "gravatar_hash": "7010f170ec917b56e173f3978c459e0e", "author_url": null, "date": "Jan 17, 2009", "message": "I had a server running NT4 with raid on SCSI - when a drive died you had to reboot to swap the SCSI order and bring the machine back up on the other drive (well it was 2000)\nI then set it to rebuild.\nUnfortunately the RAID worked on the SCSI ID and windows only knows the boot order - so it happily copied the dead drive over the top of the working one!"}, {"author_name": "InSciTek Jeff", "gravatar_hash": "3c7db1077ce759e22c54d235054182dc", "author_url": null, "date": "Jan 18, 2009", "message": "In my opinion there is only one right way to do RAID assuming your need/desire for going with RAID is for the uptime (as opposed to just performance ala RAID-0 stripe).\n\nFirst, you need a real hardware based RAID controller with it's own embedded controller that manages the array. This controller will have it's own cache and also have integrated battery backup for that cache to ensure coherency of the volumes, etc. if the system goes down for ANY reason at ANY time.\n\nSecond, the RAID chassis needs to support hot swapping of the drives. Lack of hot swap drive bays defeats the entire purpose of going with RAID in my opinion. People think of limping along on one drive until they can do a controlled shutdown and replace the original drive, but this is a fallacy. The probability of another drive failing during this time is too high. And if another does fail, now you are really !!DOWN!! until you restore from backups, etc. and you have lost at least some data!\n\nThird, you need to have a hot spare in the array. Again, because of the likelihood of another failure you need to have the rebuild start immediately and automatically. Additionally, you should replace the failed drive ASAP so it can become the new hot spare.\n\nFinally, you should not be waiting for drive failures to be doing the swaps. Server drives have a rated life and they should be periodically rotated out at or somewhat short of their rated life. Check your drive specs - its usually 3 to 5 years.\n\nMoral of story: Buy a REAL server class machine with hardware RAID, hot swappable drives, hot swap power supplies and ideally hot swap fans. The hardware is cheap compared to people time, business down time and ultimately resulting peace of mind."}, {"author_name": "InSciTek Jeff", "gravatar_hash": "3c7db1077ce759e22c54d235054182dc", "author_url": null, "date": "Jan 18, 2009", "message": "PS to Jeff: You should never \"just pull\" an in-use drive from the array. You will get away with it most of the time, but sometime you won't. The drive should be an already failed drive OR it should be manually marked off-line via the management application to remove it from the active set. With the newer SAS point to point RAID systems, this is (probably) less likely to be a real concern, but on bused SCSI RAID arrays, it is possible you can cause bad read or writes to other drives on the bus when you do that if not on the one being pulled."}, {"author_name": "Steve Sheldon", "gravatar_hash": "23a28f6ede358f8ac229a652b0b13d51", "author_url": null, "date": "Jan 18, 2009", "message": "You know the running argument you've had with Joel Spolsky about learning C?  I've been convinced for years, and your blog articles confirm it, that developers should understand infrastructure."}, {"author_name": "Joseph", "gravatar_hash": "8a71d77a2ff75e4c5449c21e29c7752f", "author_url": null, "date": "Jan 18, 2009", "message": "Jeff, have you installed the OS drivers?  I believe some features will not work correctly until you do.  Hotswap might be one of them."}, {"author_name": "Baishampayan Ghose", "gravatar_hash": "8aa4490274249db8981283bdadb2ec2b", "author_url": null, "date": "Jan 19, 2009", "message": "Eww! RAID on MS Windows seems to be a huge pain. GNU/Linux FTW!"}, {"author_name": "Robin Day", "gravatar_hash": "218d33fcf91ab66b2f86276e229cd850", "author_url": "http://www.advorto.com", "date": "Jan 19, 2009", "message": "I agree with InSciTek, if you feel you need RAID then you need to do it right. There is certainly a lot of uses for entry level servers, however, in my experience, you can pay 3-4 times the price and get an enterprise level server that will amaze you when you first set it up. The fact that you needed to write this post would already have scared me to much to rely on the system.\n\nAs also mentioned, just \"pulling\" the drives in order to test your RAID setup isn't ideal unless you plan on completely wiping all drives and starting again from scratch.\n\nRobin"}, {"author_name": "Jeff Atwood", "gravatar_hash": "51d623f33f8b83095db84ff35e15dbe8", "author_url": "http://www.codinghorror.com/blog/", "date": "Jan 19, 2009", "message": "> Moral of story: Buy a REAL server class machine with hardware RAID, hot swappable drives, hot swap power supplies and ideally hot swap fans.\n\nGo download the Lenovo RD120 PDF, because it has everything in that list -- and it's our DB server! Unfortunately RAID port #6 is perma-bad on that machine (sigh, confirmed with multiple good drive swaps), so there goes your theory of paying a lot for a perfect server.\n\n> There is certainly a lot of uses for entry level servers\n\nRobin, you realize that Google was launched and ran for several years on entirely homebuilt servers, right?\n\nhttp://www.codinghorror.com/blog/archives/000814.html\n\nThese are for the web tier."}, {"author_name": "Eric Z. Beard", "gravatar_hash": "62cc585b9fd3ee7182dadbd09a7f4b47", "author_url": null, "date": "Jan 19, 2009", "message": "@InSciTek, where do you get 3 to 5 years?  The MTF for a burned-in server hard drive is something like 150 years.  If a drive is going to fail, it usually does it within the first few weeks.\n\nAnd @Jeff, \n\n&gt;&gt; so there goes your theory of paying a lot for a perfect server.\n\nYou didn't pay a lot for that server.  Not even close to a lot.  I'm surprised you would say that.  You went for the most inexpensive solution possible.\n\nThe comment about Google is completely irrelevant.  They had an incredible architecture built around redundancy, distribution, and failover, to make the loss of a single machine nearly pain-free.  You are putting all of your eggs into one basket with the database server.  You can't take chances with that."}, {"author_name": "oliver", "gravatar_hash": "4f02b8f7945a65a746f6245c184d241d", "author_url": null, "date": "Jan 19, 2009", "message": "\"Well, both drives were IBM Deskstar DTLA-307045, aka. Deathstar. Both failed on the same day. Sadly, the second one failed before we could replace the first one.\"\n\nSo it seems advisable to use drives from different manufacturers in a mirrored RAID, to lower the chance of both drives being from a bad charge. OTOH I've heard rumors that hardware RAID controllers work best with two identical drives."}, {"author_name": "Simon", "gravatar_hash": "c83e213eaa13bd5381934a0126a64d9e", "author_url": "http://www.credecard.com", "date": "Jan 19, 2009", "message": "As many have said, you shouldn't need a reboot, and the server you have bought seems to support hotswap assuming you have hotswap drives.  I'd drop IBM a line!"}, {"author_name": "Anthony DeRobertis", "gravatar_hash": "05b48b72766177b3b0a6ff4afdb70790", "author_url": null, "date": "Jan 19, 2009", "message": "@Jeff: If you have a bad port, first check the cables. Cables are pretty cheap; replace the SATA cable going from the RAID card to the backplane. Confirm that the power cable is seated (if each port has its own power connection). Second, confirm that no packing material (e.g., Styrofoam) got in the connectors; compressed air may be able to remove it w/o damaging the connector. Finally, replace the backplane or the RAID card. Honestly, you paid good money for a working server, tell the seller to fix it. Surely its under warranty.\n\n@Jeff (again): Also, I've used plenty of hot-swap hardware, and you should not have to reboot. That's ridiculous. Also, you should be able to adjust the rebuild time. There is a trade-off between performance during rebuild and rebuild speed, of course. And the RAID config you're using will affect the rebuild speed, and also the performance impact. Please tell me you're using RAID-10 on the database, and definitely not RAID-5/6.\n\n@Eric: You have completely misunderstood what MTBF means. A MTBF of 1,000,000 hours means that if you had 1,000,000 drives, all of them past their break-in period and before their end-of-life, you'd have one failure per hour (on average). In general, you have a lot of failures at first (the break in period, from manufacturing defects), few failures in the middle, then a lot of failures at the end (the end of life). The MTBF only talks about the middle period. The end of life for drives is 3 to 7 years, depending on quality and usage. You don't honestly expect a drive to last 114 years, right?"}, {"author_name": "Eric Z. Beard", "gravatar_hash": "62cc585b9fd3ee7182dadbd09a7f4b47", "author_url": null, "date": "Jan 20, 2009", "message": "@Anthony, no I don't expect them to last over a hundred years, but I surely expect them to last longer than 3 to 7 years.  \n\nAfter Google published that paper about their drives and how often they fail, everyone is in a panic.  But remember, Google uses cheap, crappy servers and cheap, crappy drives, since they have such an incredible amount of redundancy.\n\nThe rest of us rely on just a few critical servers (and therefore few drives), so we need them to last a bit longer on average.  A burned-in SAS drive will normally last longer than the equipment it's sitting in.  \n\nI disagree with pre-emptively swapping out old drives, because pretty much every hardware failure I've ever seen in a production environment was related to new equipment, or some kind of physical re-configuration.  Your chances of introducing a problem with new drives are much higher than your 3-7 year old drive suddenly dying.  Just use RAID with spares available (hot or cold), and replace drives as needed."}, {"author_name": "Anthony DeRobertis", "gravatar_hash": "05b48b72766177b3b0a6ff4afdb70790", "author_url": null, "date": "Jan 20, 2009", "message": "@Eric: I'm not sure which paper you're referring to; however, I think we're in broad agreement then: I certainly wouldn't go swapping drives just because they've hit X years old. I only swap a drive if (a) it failed or is flaky (e.g., random timeouts); (b) SMART is giving a pre-fail warning (not just old age warning, though that'll certainly make me confirm I have a spare on hand!); (c) to upgrade to a bigger/faster drive."}, {"author_name": "Abdu", "gravatar_hash": "823048c003a3159b3adc1ee146b91114", "author_url": null, "date": "Jan 21, 2009", "message": "I have a few servers running Mylex Acceleraid (old stuff) controllers in Raid 1. If a hard drive goes offline for any reason, first make sure it's not a physical problem with the drive. In my case sometimes when a machine is cold rebooted using the power switch, it knocks out one of the drives and I have to bring it online and rebuild it.\nI use 15K scsi drives for fast seek times and writes. I had these drives for years, before SATA drives were introduced.\n\nI wonder if SCSI drives and high end SATA drives are comparable now and if SCSI lost their edge."}, {"author_name": "InSciTek Jeff", "gravatar_hash": "3c7db1077ce759e22c54d235054182dc", "author_url": null, "date": "Jan 21, 2009", "message": "@Eric and @Anthony: The 1,000,000 hour MTBF kind of ratings is actually very specific and you need to read the fine print for them very carefully. In actuality, it is more of a marketing spec than a useful technical specification.\n\nTypically, To @Anthony's point, they are actually for the middle of the curve post the infant mortality period and prior to the \"service life\" expiring, and they make very specific assumptions in the spec about how many times the drives are cycled up from a stop, etc. (Power cycles on the drives dramatically affects life).\n\nIn effect, the 1,000,000 hours is achieved as a mean reliability if you first burn in the drive, run it continuously for its service life of say 5 years, replace it with a new burned in drive at that point and keep doing that over and over. On average you will get to 1M hours before you get your first \"unexpected random\" failure. But very clearly no single drive is going to last 1M hours....not even close.\n\n@Eric, to your point the drives will likely last (perhaps years) beyond the 5 year service life point, but the probability of failure is increasing DRAMATICALLY with time.\n\nAdditionally, in a RAID array, the drives tend to be of the same vintage. Not only is the failure rate going up dramatically with time, but there is a relatively strong correlation in failure times. ie: It's not all that unlikely more than one drive will fail within a few hours or days of each other especially when say there are 5 or 10 drives in the same array."}, {"author_name": "Aaron Wetherhold", "gravatar_hash": "efc7a06f93b76251d63dba00ca33debb", "author_url": null, "date": "Jan 22, 2009", "message": "@Eric\n&gt;&gt; You didn\u2019t pay a lot for that server. Not even close &gt;&gt; to a lot. I\u2019m surprised you would say that. You went &gt;&gt; for the most inexpensive solution possible.\n\nI had to laugh when I read this because I was thinking the exact same thing.\n\n@Jeff\nBest of luck with the drive speed (from last week's post) and the RAID hot swapping (this week's post).  I do hope it works the way you want it to.  I'm skeptical only because I gone down the same road as to what you're doing (buying a less expensive server, putting in my own drives, find the drive carrier, etc, etc) and it turned out to be so much extra work.  \nOne server the 7200 RPM drives killed me, on another server there was some weird conflict between the SAS drives and the RAID card.  The SCSI bus would reset during high load.  The drive manufacture and the RAID controller both blamed each other, it was a mess.  \n\nI've learned to pick one vendor and then buy the server pre-built in it's entirety, along with a descent service warranty, but that's just my experience.  You might have better luck."}, {"author_name": "Jeff Atwood", "gravatar_hash": "51d623f33f8b83095db84ff35e15dbe8", "author_url": "http://www.codinghorror.com/blog/", "date": "Jan 25, 2009", "message": "> You didn\u2019t pay a lot for that server. Not even close to a lot. \n\nWell, the $6500+ is coming directly out of my bank account. And that's a lot to me.\n\nBuilding SuperMicro style (ala Google) would have been cheaper. But I would have had to give up the dual power supplies.\n\nThe servers actually aren't that expensive; it's all the parts they gouge you for, and any recurring service contracts, that really cost."}]}